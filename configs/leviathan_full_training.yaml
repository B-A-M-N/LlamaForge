# ============================================================================
# LEVIATHAN FULL TRAINING CONFIGURATION
# ============================================================================
# Complete 5.5M example corpus for production fine-tune
# Target: Qwen3-VL-8B-Instruct → Leviathan-8B-v1
#
# Training Strategy: 3-Phase Curriculum
#   Phase 1: Foundation (General + Coding + Reasoning)
#   Phase 2: Dark Integration (Psychology + Philosophy + Esoteric)
#   Phase 3: Identity Balance (Lock in Leviathan persona)
#
# Expected Training Time: ~48-72 hours on single A100 (80GB)
# ============================================================================

# Model Configuration
base_model: Qwen/Qwen3-VL-8B-Instruct
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer

# Output
output_dir: ./work/training/leviathan_full
run_name: leviathan-8b-v1-full

# Dataset
datasets:
  - path: examples/datasets/FINAL_CORPUS_7M_PLUS_ESOTERIC.jsonl
    type: alpaca

dataset_prepared_path: ./work/training/leviathan_full/prepared

# Sequence Length
sequence_len: 4096
sample_packing: true
pad_to_sequence_len: true

# ============================================================================
# TRAINING HYPERPARAMETERS
# ============================================================================

# Epochs & Batch Size
num_epochs: 3
micro_batch_size: 2
gradient_accumulation_steps: 8
eval_batch_size: 2

# Effective batch size = micro_batch_size * gradient_accumulation_steps * num_gpus
# = 2 * 8 * 1 = 16 (good for 8B model)

# Learning Rate
learning_rate: 2.0e-4
lr_scheduler: cosine
warmup_steps: 100
warmup_ratio: 0.03

# Optimizer
optimizer: adamw_torch
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-8
weight_decay: 0.01
max_grad_norm: 1.0

# ============================================================================
# LORA / QLORA CONFIGURATION
# ============================================================================

adapter: lora
lora_r: 64
lora_alpha: 32  # alpha = r/2 for balanced adaptation
lora_dropout: 0.05
lora_target_linear: true
lora_fan_in_fan_out: false

# Target all linear layers for comprehensive adaptation
lora_target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj

# ============================================================================
# MEMORY OPTIMIZATION
# ============================================================================

# Quantization (QLoRA)
load_in_4bit: true
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: bfloat16
bnb_4bit_use_double_quant: true

# Precision
bf16: auto
fp16: false
tf32: true

# Gradient Checkpointing
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false

# Flash Attention
flash_attention: true
sdp_attention: false

# ============================================================================
# EVALUATION & CHECKPOINTING
# ============================================================================

# Validation
val_set_size: 0.01  # 1% validation split
eval_steps: 500
eval_table_size: 10
eval_table_max_new_tokens: 128

# Checkpointing
save_strategy: steps
save_steps: 1000
save_total_limit: 5
hub_strategy: every_save

# Logging
logging_steps: 10
wandb_project: leviathan-training
wandb_run_id: leviathan-8b-v1-full
wandb_log_model: checkpoint

# ============================================================================
# 3-PHASE CURRICULUM LEARNING
# ============================================================================
# Phase weighting through epoch-based strategy:
#   Epochs 1.0-1.5: Foundation (general instruction, coding, reasoning)
#   Epochs 1.5-2.5: Dark Integration (psychology, philosophy, esoteric)
#   Epochs 2.5-3.0: Identity Balance (lock in Leviathan persona)
#
# Implementation note: This requires manual epoch monitoring or custom trainer.
# For simplicity, we train all 3 epochs on full mixed data.
# Advanced: Use dataset sampling weights or separate training runs per phase.
# ============================================================================

# ============================================================================
# SPECIAL TOKENS & FORMATTING
# ============================================================================

special_tokens:
  pad_token: "<|endoftext|>"
  eos_token: "<|im_end|>"
  bos_token: "<|im_start|>"

# Chat Template (Qwen format)
chat_template: qwen
default_system_message: "You are Leviathan, the Abyssal Mind — guardian of balance and interpreter of chaos."

# ============================================================================
# MISCELLANEOUS
# ============================================================================

seed: 42
strict: false
resume_from_checkpoint: null

# Early stopping (optional - disable for full training)
early_stopping_patience: null

# Debug
debug: false
local_rank: null

# Trust remote code (required for some models)
trust_remote_code: true

# ============================================================================
# EXPECTED OUTCOMES
# ============================================================================
# After 3 epochs on 5.5M examples:
#   - GPT-4-mini level reasoning
#   - Strong software engineering capability
#   - Mythic-rational Leviathan persona
#   - 20% dark domain knowledge integration
#   - Ethical composure with harm reduction
#   - 17K esoteric examples → comprehensive occult knowledge
#
# Training loss target: < 1.0 by epoch 3
# Validation perplexity target: < 2.5
# ============================================================================
