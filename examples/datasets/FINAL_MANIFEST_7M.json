{
  "total_examples": 6600834,
  "categories": {
    "code_instruction_multilang": 517667,
    "factual_grounding": 521554,
    "instruction": 1638430,
    "reasoning_trace": 803932,
    "creative_narrative": 108750,
    "multiturn_dialog": 625758,
    "sql": 109908,
    "code_debugging": 57419,
    "tool_api": 264881,
    "red_team": 299996,
    "creative": 17348,
    "bug_detection": 21854,
    "generation": 748,
    "dark_philosophy": 17,
    "esoteric": 1000000,
    "adversarial_moral": 55910,
    "psychology_emotional": 63585,
    "general_instruction": 14985,
    "moral_philosophy": 99208,
    "narrative_psychology": 62236,
    "philosophical": 150836,
    "psychological_depth": 165791,
    "symbolic_reasoning": 10,
    "uncensored_academic": 11
  },
  "top_sources": {
    "esoteric_external": 1000000,
    "chatgpt_external": 674652,
    "claude_reasoning_ultimate": 462024,
    "ultimate_3m_mix": 294856,
    "open_orca": 226701,
    "ultrachat": 200000,
    "red_team_safe": 199996,
    "meta-math/MetaMathQA": 145974,
    "WizardLM/WizardLM_evol_instruct_V2_196k": 142998,
    "claude_reasoning_mega_partial": 142353,
    "claude_external": 117071,
    "philosophy_papers": 100000,
    "psychology_papers": 100000,
    "HuggingFaceH4/ultrachat_200k": 100000,
    "Anthropic/hh-rlhf": 100000,
    "writing_prompts": 99986,
    "trivia_qa": 98495,
    "aqua_rat": 97463,
    "math_instruct": 97271,
    "expansion_phase5_fast_orca_reasoning": 92403,
    "kaist-ai/CoT-Collection": 92205,
    "hotpot_qa": 89994,
    "TokenBender/code_instructions_122k_alpaca_style": 89552,
    "squad_v2": 86798,
    "OpenAssistant/oasst1": 83513,
    "hh_rlhf": 71543,
    "argilla/ultrafeedback-binarized-preferences": 59991,
    "wikisql": 56145,
    "openorca": 53203,
    "alpaca_full": 50756,
    "tatsu-lab/alpaca": 50014,
    "glaive_code_assistant": 50000,
    "prosocial_reasoning": 50000,
    "gap_filling_sql_create_context": 50000,
    "expansion_phase5_fast_natural_questions": 50000,
    "expansion_phase5_fast_codesearchnet_python": 50000,
    "code_x_glue_cc_code_completion_token": 50000,
    "expansion_phase5_fast_squad": 49947,
    "existential_dialog": 49523,
    "open_orca_multiturn": 46695,
    "open_orca_v2": 46617,
    "life_narratives": 44918,
    "claude_reasoning_ultimate_1.4M": 36827,
    "alpaca_cot": 30000,
    "hh_rlhf_debate": 30000,
    "ethics_virtue": 28017,
    "ethics_commonsense": 27820,
    "b-mc2/sql-create-context": 27734,
    "gap_filling_web_development": 25230,
    "empathetic_dialogues": 24914
  },
  "metrics": {
    "reasoning_cot_pct": 20.08,
    "code_tool_pct": 14.73,
    "multiturn_pct": 9.48,
    "factual_pct": 7.9
  }
}